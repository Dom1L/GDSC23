{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb38369-d552-4b89-b36e-a26187e8b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt \n",
    "from timm import create_model, list_models\n",
    "import lightning as L\n",
    "\n",
    "from gdsc.data import AudioDataset, DataModule\n",
    "from gdsc.trainer import TrainModule\n",
    "from gdsc.net import SampleNet\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca120bac-d04c-4adc-9c37-50468dcde1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f5b8de-21c0-40af-9389-0b11449d6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace()\n",
    "\n",
    "# paths\n",
    "# cfg.data_folder = ''\n",
    "# cfg.name = \n",
    "# cfg.data_dir = \n",
    "# cfg.train_data_folder = cfg.data_dir + \"train_audio/\"\n",
    "# cfg.val_data_folder = cfg.data_dir + \"train_audio/\"\n",
    "# cfg.output_dir = \n",
    "\n",
    "# dataset\n",
    "# cfg.dataset = \"base_ds\"\n",
    "# cfg.min_rating = 0\n",
    "# cfg.val_df = None\n",
    "# cfg.batch_size_val = 1\n",
    "# cfg.train_aug = None\n",
    "# cfg.val_aug = None\n",
    "# cfg.test_augs = None\n",
    "# cfg.wav_len_val = 5  # seconds\n",
    "# cfg.min_rating = 2.0\n",
    "# cfg.wav_crop_len = 30  # seconds\n",
    "# audio\n",
    "cfg.img_height = 256\n",
    "cfg.img_weight = 512\n",
    "cfg.window_size = 2048\n",
    "cfg.sample_rate = 32000\n",
    "cfg.fmin = 16\n",
    "cfg.fmax = 16386\n",
    "cfg.power = 2\n",
    "cfg.mel_bins = cfg.img_height\n",
    "cfg.hop_size = 512 # int(cfg.sample_rate * cfg.wav_crop_len / (cfg.img_weight - 1))\n",
    "cfg.top_db = 80.0\n",
    "\n",
    "# img model\n",
    "\n",
    "cfg.pretrained = False\n",
    "cfg.pretrained_weights = None\n",
    "cfg.train = True\n",
    "cfg.val = False\n",
    "cfg.in_chans = 1\n",
    "\n",
    "cfg.alpha = 1\n",
    "cfg.eval_epochs = 1\n",
    "cfg.eval_train_epochs = 1\n",
    "cfg.warmup = 0\n",
    "\n",
    "cfg.mel_norm = False\n",
    "\n",
    "cfg.label_smoothing = 0\n",
    "\n",
    "cfg.remove_pretrained = []\n",
    "\n",
    "# training\n",
    "cfg.seed = 123\n",
    "cfg.save_val_data = True\n",
    "\n",
    "# ressources\n",
    "# cfg.mixed_precision = True\n",
    "# cfg.gpu = 0\n",
    "# cfg.num_workers = 4 # 18\n",
    "# cfg.drop_last = True \n",
    "\n",
    "cfg.n_classes = 8\n",
    "\n",
    "\n",
    "# training \n",
    "cfg.lr = 0.001\n",
    "cfg.epochs = 5\n",
    "cfg.batch_size = 1\n",
    "cfg.batch_size_val = 1\n",
    "cfg.backbone = \"resnet34\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5de9bc-8677-43d6-86f7-166804428399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:197: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(data_dir=r'C:\\Users\\dolemm\\OneDrive - Capgemini\\Documents\\work\\train_audio', batch_size=1)\n",
    "model = SampleNet(cfg)\n",
    "tmod = TrainModule(model, loss_fn=nn.BCEWithLogitsLoss(reduction=\"none\"), optimizer_name='Adam', optimizer_hparams={\"lr\": cfg.lr, \"weight_decay\": 1e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775edb0e-4803-4d36-8349-c664663c4b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | model   | SampleNet         | 21.3 M\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.130    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\dolemm\\AppData\\Local\\anaconda3\\envs\\GDSC23\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [00:04<00:00,  1.71it/s, v_num=9]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 7/7 [03:49<00:00, 32.85s/it, v_num=9]81s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 7/7 [00:03<00:00,  1.82it/s, v_num=9]       \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 7/7 [03:46<00:00, 32.35s/it, v_num=9]84s/it]\u001b[A\n",
      "Epoch 2: 100%|██████████| 7/7 [00:03<00:00,  1.81it/s, v_num=9]       \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 7/7 [03:47<00:00, 32.46s/it, v_num=9]88s/it]\u001b[A\n",
      "Epoch 3: 100%|██████████| 7/7 [00:03<00:00,  1.79it/s, v_num=9]       \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 7/7 [03:47<00:00, 32.50s/it, v_num=9]91s/it]\u001b[A\n",
      "Epoch 4: 100%|██████████| 7/7 [00:03<00:00,  1.83it/s, v_num=9]       \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 7/7 [03:47<00:00, 32.52s/it, v_num=9]76s/it]\u001b[A\n",
      "Epoch 4: 100%|██████████| 7/7 [03:47<00:00, 32.52s/it, v_num=9]       \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [07:29<00:00, 64.21s/it, v_num=9]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    ")\n",
    "trainer.fit(tmod, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78be9c9-5cae-4461-8d15-97f59f0f015f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\dolemm\\appdata\\local\\anaconda3\\envs\\gdsc23\\lib\\site-packages\\lightning\\pytorch\\core\\module.py\u001b[0m(617)\u001b[0;36m__to_tensor\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    615 \u001b[1;33m        )\n",
      "\u001b[0m\u001b[1;32m    616 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 617 \u001b[1;33m            raise ValueError(\n",
      "\u001b[0m\u001b[1;32m    618 \u001b[1;33m                \u001b[1;34mf\"`self.log({name}, {value})` was called, but the tensor must have a single element.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    619 \u001b[1;33m                \u001b[1;34mf\" You can try doing `self.log({name}, {value}.mean())`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\dolemm\\appdata\\local\\anaconda3\\envs\\gdsc23\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m(51)\u001b[0;36mapply_to_collection\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     49 \u001b[1;33m    \u001b[1;31m# Breaking condition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     50 \u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 51 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     52 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     53 \u001b[1;33m    \u001b[0melem_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\dolemm\\appdata\\local\\anaconda3\\envs\\gdsc23\\lib\\site-packages\\lightning\\pytorch\\core\\module.py\u001b[0m(444)\u001b[0;36mlog\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    442 \u001b[1;33m            )\n",
      "\u001b[0m\u001b[1;32m    443 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 444 \u001b[1;33m        \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    445 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    446 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_reset_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\dolemm\\pycharmprojects\\gdsc23\\gdsc\\trainer.py\u001b[0m(51)\u001b[0;36mtraining_step\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     49 \u001b[1;33m        \u001b[1;31m# Logs the accuracy per epoch to tensorboard (weighted average over batches)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     50 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 51 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     52 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m  \u001b[1;31m# Return tensor to call \".backward\" on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     53 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6477, 0.5741, 0.7184, 0.9730, 0.8726, 0.7642, 0.7386, 0.5637]],\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'label' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ll\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m     42 \u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     43 \u001b[0m        \u001b[1;31m# \"batch\" is the output of the training data loader.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     44 \u001b[0m        \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     45 \u001b[0m        \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     46 \u001b[0m        \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     47 \u001b[0m        \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     48 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     49 \u001b[0m        \u001b[1;31m# Logs the accuracy per epoch to tensorboard (weighted average over batches)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     50 \u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 51 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m  \u001b[1;31m# Return tensor to call \".backward\" on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     53 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0930, -0.2543,  0.0499,  0.4983,  0.3316,  0.1375,  0.0889, -0.2782]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  preds.sigmoid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5232, 0.4368, 0.5125, 0.6221, 0.5822, 0.5343, 0.5222, 0.4309]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6477, 0.5741, 0.7184, 0.9730, 0.8726, 0.7642, 0.7386, 0.5637]],\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  acc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0930, -0.2543,  0.0499,  0.4983,  0.3316,  0.1375,  0.0889, -0.2782]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  preds.sigmoid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5232, 0.4368, 0.5125, 0.6221, 0.5822, 0.5343, 0.5222, 0.4309]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss.mean(dim=1).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7315, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e821fa6-75c8-4ed5-b68d-f89c5cc8c6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.2418e-06,  8.5255e-06, -1.2656e-05,  ...,  1.1560e-05,\n",
       "            4.1606e-05,  5.7300e-06]]]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.val.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb0786-cafb-4019-800a-cfd666c6df43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
